{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q git+https://github.com/huggingface/transformers.git pytube ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victordibia/miniconda3/envs/autog/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "2024-07-04 18:12:27.703410: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-04 18:12:27.703459: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-04 18:12:27.704221: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-04 18:12:27.710061: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-04 18:12:28.389639: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import RTDetrForObjectDetection, RTDetrImageProcessor\n",
    "\n",
    "\n",
    "image_processor = RTDetrImageProcessor.from_pretrained(\"PekingU/rtdetr_r50vd_coco_o365\")\n",
    "model = RTDetrForObjectDetection.from_pretrained(\"PekingU/rtdetr_r50vd_coco_o365\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube \n",
    "import os \n",
    "\n",
    "os.makedirs('temp', exist_ok=True)\n",
    "yt = YouTube('http://youtube.com/watch?v=2lAe1cqCOXo')\n",
    "video_path = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first().download(output_path='temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "from PIL import Image \n",
    "import os\n",
    "import tempfile\n",
    "import time \n",
    "\n",
    "os.makedirs('temp/videos', exist_ok=True)\n",
    "def extract_frames(video_path, n_frames, sample_rate=10):\n",
    "    # Get the total duration of the video\n",
    "    probe = ffmpeg.probe(video_path)\n",
    "    video_stream = next(stream for stream in probe['streams'] if stream['codec_type'] == 'video')\n",
    "    duration = float(video_stream['duration'])\n",
    "    total_frames = int(video_stream['nb_frames']) \n",
    "    print(\"Duration: \", duration, \"Total Frames: \", total_frames)\n",
    "\n",
    "    framerate = video_stream['r_frame_rate']\n",
    "    num, den = map(int, framerate.split('/'))\n",
    "    fps = num / den\n",
    "\n",
    "    print(\"Frame Rate: \", fps)\n",
    "    \n",
    "    # Calculate the time intervals to extract frames\n",
    "    # this should be the first n frames of the video calculated based on the sample rate\n",
    "    frame_times =  range(n_frames)\n",
    "    print(\"Frame Times: \", frame_times)\n",
    "     \n",
    "    \n",
    "    # Create a temporary directory to store the extracted frames\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        print(f'Created temporary directory {temp_dir}')\n",
    "        # Extract frames using ffmpeg\n",
    "        for i, t in enumerate(frame_times):\n",
    "            output_path = os.path.join(temp_dir, f'frame_{i:04d}.png')\n",
    "            (\n",
    "                ffmpeg\n",
    "                .input(video_path, ss=t)\n",
    "                .output(output_path, vframes=1)\n",
    "                .global_args('-loglevel', 'error')\n",
    "                .run(overwrite_output=True)\n",
    "            )\n",
    "        \n",
    "        # Load frames into PIL Images\n",
    "        frames = []\n",
    "        for i in range(n_frames - 1):\n",
    "            frame_path = os.path.join(temp_dir, f'frame_{i:04d}.png')\n",
    "            with Image.open(frame_path) as img:\n",
    "                frames.append(img.copy())\n",
    "        return frames\n",
    "\n",
    "COLORS = [[0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],\n",
    "          [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]]\n",
    " \n",
    "def plot_results(pil_img, scores, labels, boxes, output_path, fps, score_threshold=0.6):\n",
    "    img_aspect_ratio = (pil_img.width / pil_img.height)\n",
    "    plt.figure(figsize=(16, int(16 // img_aspect_ratio)))\n",
    "    plt.imshow(pil_img)\n",
    "    ax = plt.gca()\n",
    "    colors = COLORS * 100\n",
    "    for score, label, (xmin, ymin, xmax, ymax),c  in zip(scores.tolist(), labels.tolist(), boxes.tolist(), colors):\n",
    "        if score > score_threshold:\n",
    "            ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                        fill=False, color=c, linewidth=3))\n",
    "                \n",
    "            text = f'{model.config.id2label[label]}: {score:0.2f}'\n",
    "            \n",
    "            # Change text position and alignment\n",
    "            ax.text(xmax, ymin, text, fontsize=15,\n",
    "                    bbox=dict(facecolor='yellow', alpha=0.5),\n",
    "                    horizontalalignment='right', verticalalignment='top')\n",
    "    # plot fps in a box lower left  \n",
    "    ax.text(0.01, 0.97, f'FPS: {fps:0.2f}', color='red', fontsize=15, transform=ax.transAxes, ha='left')\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path,   pad_inches=0, dpi=100) \n",
    "    plt.close()\n",
    "\n",
    "def process_image_frame(image, output_dir='temp/frames', index=0,scrore_threshold=0.5):\n",
    "    start_time = time.time()\n",
    "    inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    results = image_processor.post_process_object_detection(outputs, target_sizes=torch.tensor([image.size[::-1]]), threshold=scrore_threshold)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    # print(f\"Elapsed Time: {elapsed_time}\")\n",
    "    fps = int(1/elapsed_time)\n",
    "\n",
    "    output_path = os.path.join(output_dir, f'frame_{index:04d}.png')\n",
    "    for result in results:\n",
    "        plot_results(image, result[\"scores\"], result[\"labels\"], result[\"boxes\"], output_path, fps)\n",
    "    \n",
    "\n",
    "\n",
    "# url = 'https://i.pinimg.com/originals/39/6f/b9/396fb90286728d6573405c60941043e1.jpg'\n",
    "# image = Image.open(requests.get(url, stream=True).raw)\n",
    "# process_image_frame(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames = extract_frames(video_path, n_frames=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:08<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def process_video(video_path, n_frames, output_dir='temp/frames', sample_rate=10):\n",
    "    frames = extract_frames(video_path, n_frames, sample_rate)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for i in tqdm(range(len(frames))):\n",
    "        process_image_frame(frames[i], output_dir=output_dir, index=i,scrore_threshold=0.3)\n",
    "    return frames\n",
    "output_dir = 'temp/videos/output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "for i in tqdm(range(len(frames[:10]))):\n",
    "    process_image_frame(frames[i], output_dir=output_dir, index=i,scrore_threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "def images_to_video(directory, output_file='output.mp4', loglevel='error', fps=1):\n",
    "    \"\"\"\n",
    "    Create a video from sorted PNG images in a directory.\n",
    "\n",
    "    :param directory: Path to the directory containing PNG images.\n",
    "    :param output_file: Path to the output video file (default is 'output.mp4').\n",
    "    :param loglevel: FFmpeg logging level (default is 'error').\n",
    "    :param fps: Frames per second (default is 1).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure the provided directory exists\n",
    "    if not os.path.isdir(directory):\n",
    "        raise ValueError(f\"The provided directory '{directory}' does not exist.\")\n",
    "\n",
    "    # Get list of all .png files in the directory\n",
    "    png_files = glob.glob(os.path.join(directory, '*.png'))\n",
    "\n",
    "    # Sort the files\n",
    "    png_files.sort()\n",
    "\n",
    "    if not png_files:\n",
    "        raise ValueError(f\"No .png files found in the directory '{directory}'.\")\n",
    "\n",
    "    # Start building the ffmpeg input\n",
    "    input_stream = ffmpeg.input('pipe:', format='image2pipe', vcodec='png', r=fps)\n",
    "\n",
    "    # Set up the ffmpeg output with reduced verbosity\n",
    "    output = ffmpeg.output(input_stream, output_file, vcodec='libx264', pix_fmt='yuv420p').global_args('-loglevel', loglevel, '-y')\n",
    "\n",
    "    # Run the ffmpeg command\n",
    "    process = output.run_async(pipe_stdin=True)\n",
    "\n",
    "    # Write each image to the process standard input\n",
    "    for file in png_files:\n",
    "        with open(file, 'rb') as f:\n",
    "            process.stdin.write(f.read())\n",
    "\n",
    "    # Close the standard input to complete the streaming\n",
    "    process.stdin.close()\n",
    "    process.wait()\n",
    "\n",
    "    print(f\"Video file created: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video file created: temp/videos/output.mp4\n"
     ]
    }
   ],
   "source": [
    "images_to_video(output_dir, 'temp/videos/output.mp4', fps=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
